{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense,Input,Dropout,GaussianNoise\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import StratifiedKFold,RepeatedStratifiedKFold,train_test_split,KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from pandas import DataFrame\n",
    "from time import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from docopt import docopt\n",
    "from utils import  load_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train,x_valid, y_valid,x_test, y_test=[],[],[],[],[],[]\n",
    "X,Y=[],[]\n",
    "experiments=['cc200_whole']\n",
    "with h5py.File(\"data/sample.hdf5\".encode('utf-8'), \"r\") as hdf5:\n",
    "        \n",
    "        for experiment in experiments:\n",
    "            exp_storage=hdf5[\"experiments/cc200_whole\"]\n",
    "            for fold in exp_storage:\n",
    "                \n",
    "                experiment_cv=\"{}_{}\".format(experiment,fold)\n",
    "\n",
    "                x_train, y_train, \\\n",
    "                x_valid, y_valid, \\\n",
    "                x_test, y_test = load_fold(hdf5[\"patients\"], exp_storage, fold)\n",
    "                y_train,y_valid,y_test=y_train.reshape(y_train.shape[0],1),y_valid.reshape(y_valid.shape[0],1),y_test.reshape(y_test.shape[0],1)\n",
    "                x_train, y_train,x_valid, y_valid,x_test, y_test=list(x_train), list(y_train),list(x_valid), list(y_valid),list(x_test),list(y_test)    \n",
    "                X=x_train[:]\n",
    "                Y=y_train[:]\n",
    "                for i in x_valid:\n",
    "                    X.append(i)\n",
    "                for i in y_valid:\n",
    "                    Y.append(i)\n",
    "                for i in x_test:\n",
    "                    X.append(i)\n",
    "                for i in y_test:\n",
    "                    Y.append(i)\n",
    "                X=np.array(X)\n",
    "                Y=np.array(Y)\n",
    "                break\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.15,shuffle=True,random_state=1)          \n",
    "\n",
    "p=n=0\n",
    "for i in Y_train:\n",
    "    if i[0]==1:\n",
    "        p=p+1\n",
    "    else:\n",
    "        n=n+1\n",
    "print('Training Examples: p-{} n-{}'.format(p,n))\n",
    "p=n=0\n",
    "for i in Y_test:\n",
    "    if i[0]==1:\n",
    "        p=p+1\n",
    "    else:\n",
    "        n=n+1\n",
    "print('Testing Examples:  p-{} n-{}'.format(p,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(x_train,y_train,x_test,y_test,i):\n",
    "    #callbacks\n",
    "    tensorboard=TensorBoard(log_dir='./logs/Exp1/fold_{}'.format(i))\n",
    "    Results={}\n",
    "    #Autoencoder-1 architecture\n",
    "    print(\"Constructing ae1 architecture...\",end=\"\")\n",
    "    input_size=x_train.shape[1]\n",
    "    ae1_input_layer=Input((input_size))\n",
    "    ae1_input_layer_noise=GaussianNoise(0.1)(ae1_input_layer)\n",
    "    ae1_bottle_neck=Dense(1000,activation='relu')(ae1_input_layer)\n",
    "    ae1_ouput_layer=Dense(input_size,activation='relu')(ae1_bottle_neck)\n",
    "    ae1=Model(ae1_input_layer,ae1_ouput_layer)\n",
    "    print(\"done!\")\n",
    "    print(\"Configuring ae1...\",end=\"\")\n",
    "    ae1.compile(optimizer='adam',loss='mse',metrics=['mse','mae'])\n",
    "    print(\"done!\")\n",
    "    #ae1.summary()\n",
    "\n",
    "    #Traininig ae1\n",
    "    print(\"Training ae1...\")\n",
    "    ae1.fit(x_train,x_train,epochs=50,batch_size=16,validation_split=0.1,shuffle=True)\n",
    "    print(\"done!\")\n",
    "    print(\"Evaluating and storing results of ae1...\",end=\"\")\n",
    "    temp=ae1.evaluate(x_test,x_test,verbose=2)\n",
    "    Results['ae1_loss'],Results['ae1_mse'],Results['ae1_mae']=temp[0],temp[1],temp[2]\n",
    "    print(\"done!\")\n",
    "    \n",
    "    #Saving ae1\n",
    "    print(\"Saving ae1...\",end=\"\")\n",
    "    path='SavedModels_In_h5format/Exp1/fold_{}/ae1.hdf5'.format(i)\n",
    "    ae1.save(path)\n",
    "    ae1.save('SavedModels_In_SavedModels/Exp1/fold_{}/ae1'.format(i))\n",
    "    print(\"done!\")\n",
    "    \n",
    "    #Preparing data for autoencoder-2\n",
    "    print(\"Preparing data for ae2 by loading ae1...\",end=\"\")\n",
    "    ae1_new=tf.keras.models.load_model('SavedModels_In_SavedModels/Exp1/fold_{}/ae1'.format(i))\n",
    "    ae1_encoder=Model(ae1_input_layer,ae1_bottle_neck)\n",
    "    ae1_encoder.layers[1].set_weights([ae1_new.get_weights()[0],ae1_new.get_weights()[1]])\n",
    "    ae2_X_train=ae1_encoder.predict(x_train)\n",
    "    ae2_X_test=ae1_encoder.predict(x_test)\n",
    "    print(\"done!\")\n",
    "\n",
    "    #Autoencoder-2 architecture\n",
    "    print(\"Constructing ae2 architecture...\",end=\"\")\n",
    "    input_size=ae2_X_train.shape[1]\n",
    "    ae2_input_layer=Input((input_size))\n",
    "    ae2_input_layer_noise=GaussianNoise(0.2)(ae2_input_layer)\n",
    "    ae2_bottle_neck=Dense(600,activation='relu')(ae2_input_layer)\n",
    "    ae2_ouput_layer=Dense(input_size,activation='relu')(ae2_bottle_neck)\n",
    "    ae2=Model(ae2_input_layer,ae2_ouput_layer)\n",
    "    print(\"done!\")\n",
    "    print(\"Configuring ae2...\",end=\"\")\n",
    "    ae2.compile(optimizer='adam',loss='mse',metrics=['mse','mae'])\n",
    "    print(\"done!\")\n",
    "    #ae2.summary()\n",
    "\n",
    "    #Training ae2\n",
    "    print(\"Training ae1...\",end=\"\")\n",
    "    ae2.fit(ae2_X_train,ae2_X_train,epochs=100,batch_size=16,validation_split=0.1,shuffle=True)\n",
    "    print(\"done!\")\n",
    "    print(\"Evaluating and storing results of ae2...\",end=\"\")\n",
    "    temp=ae2.evaluate(ae2_X_test,ae2_X_test,verbose=2)\n",
    "    Results['ae2_loss'],Results['ae2_mse'],Results['ae2_mae']=temp[0],temp[1],temp[2]\n",
    "    print(\"done!\")\n",
    "    #Saving ae2\n",
    "    print(\"Saving ae1...\",end=\"\")\n",
    "    ae2.save('SavedModels_In_h5format/Exp1/fold_{}/ae2.hdf5'.format(i))\n",
    "    ae2.save('SavedModels_In_SavedModels/Exp1/fold_{}/ae2'.format(i))\n",
    "    print(\"done!\")\n",
    "    \n",
    "    #Loading Models for Transfer Learning\n",
    "    print(\"Loading ae2\")\n",
    "    ae2_new=tf.keras.models.load_model('SavedModels_In_SavedModels/Exp1/fold_{}/ae2'.format(i))\n",
    "    print(\"done!\")\n",
    "    #MLP\n",
    "    print(\"Constructing architecture of mlp...\",end=\"\")\n",
    "    mlp=Sequential()\n",
    "    mlp.add(Dense(1000,activation='relu',input_dim=19900))\n",
    "    mlp.add(Dense(600,activation='relu'))\n",
    "    mlp.add(Dense(1,activation='sigmoid'))\n",
    "    print(\"done!\")\n",
    "    print(\"Configuring mlp...\",end=\"\")\n",
    "    mlp.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    print(\"done!\")\n",
    "    print(\"Freezing layers of mlp...\",end=\"\")\n",
    "    mlp.layers[0].set_weights([ae1_new.get_weights()[0],ae1_new.get_weights()[1]])\n",
    "    mlp.layers[0].trainable=False\n",
    "    mlp.layers[1].set_weights([ae2_new.get_weights()[0],ae2_new.get_weights()[1]])\n",
    "    mlp.layers[1].trainable=False\n",
    "    print(\"done!\")\n",
    "    #mlp.summary()\n",
    "    print(\"Training mlp...\",end=\"\")\n",
    "    mlp.fit(X_train,Y_train,epochs=100,batch_size=16,validation_split=0.1,shuffle=True, callbacks=[tensorboard])\n",
    "    print(\"done!\")\n",
    "    \n",
    "    print(\"Saving mlp...\",end=\"\")\n",
    "    ae2.save('SavedModels_In_h5format/Exp1/fold_{}/mlp.hdf5'.format(i))\n",
    "    ae2.save('SavedModels_In_SavedModels/Exp1/fold_{}/mlp'.format(i))\n",
    "    print(\"done!\")\n",
    "    \n",
    "    print(\"Evaluating and storing results of mlp...\",end=\"\")\n",
    "    temp=mlp.evaluate(X_test,Y_test,verbose=2)\n",
    "    Results['mlp_loss'],Results['mlp_accuracy']=temp[0],temp[1]\n",
    "    print(\"done!\")\n",
    "    return Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "i=0\n",
    "skf = StratifiedKFold(10, shuffle=True)\n",
    "for i, (train, test) in enumerate(skf.split(X, Y)):\n",
    "        print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "        x_train=np.array([X[i] for i in train])\n",
    "        y_train=np.array([Y[i] for i in train])\n",
    "        x_test=np.array([X[i] for i in test])\n",
    "        y_test=np.array([Y[i] for i in test])\n",
    "        print(train_and_evaluate_model(x_train,y_train,x_test,y_test,i+1))\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold_1\n",
    "{'ae1_loss': 0.04122388821381789, 'ae1_mse': 0.041223887, 'ae1_mae': 0.16235116, 'ae2_loss': 0.00983807473228528, \n",
    " 'ae2_mse': 0.009838074, 'ae2_mae': 0.0044339993, \n",
    " 'mlp_loss': 2.2273578490966406, 'mlp_accuracy': 0.69871795}\n",
    "#fold_2\n",
    "{'ae1_loss': 0.041735986390939124, 'ae1_mse': 0.041735984, 'ae1_mae': 0.16299812, 'ae2_loss': 0.00568302097515418, \n",
    " 'ae2_mse': 0.0056830207, 'ae2_mae': 0.002652438, \n",
    " 'mlp_loss': 2.457437793413798, 'mlp_accuracy': 0.6923077}\n",
    "#fold_3\n",
    "{'ae1_loss': 0.041662152856588364, 'ae1_mse': 0.041662153, 'ae1_mae': 0.16314024, 'ae2_loss': 0.003184114332095935,\n",
    " 'ae2_mse': 0.0031841146, 'ae2_mae': 0.0019735892, \n",
    " 'mlp_loss': 2.4281914356427317, 'mlp_accuracy': 0.6602564}\n",
    "#fold_4\n",
    "{'ae1_loss': 0.04324208257290033, 'ae1_mse': 0.043242082, 'ae1_mae': 0.16591014, 'ae2_loss': 0.0021350136420761165,\n",
    " 'ae2_mse': 0.0021350137, 'ae2_mae': 0.0016863676, \n",
    " 'mlp_loss': 2.5261729863973765, 'mlp_accuracy': 0.67948717}\n",
    "#fold_5\n",
    "{'ae1_loss': 0.04028723560846769, 'ae1_mse': 0.040287238, 'ae1_mae': 0.16018154, 'ae2_loss': 0.0011480520512962427, \n",
    " 'ae2_mse': 0.001148052, 'ae2_mae': 0.0016268685, \n",
    " 'mlp_loss': 2.4056292191529884, 'mlp_accuracy': 0.6858974}\n",
    "#fold_6\n",
    "{'ae1_loss': 0.04346959274804708, 'ae1_mse': 0.04346959, 'ae1_mae': 0.1668984, 'ae2_loss': 0.0031298403311701656, \n",
    " 'ae2_mse': 0.0031298404, 'ae2_mae': 0.0025571962, \n",
    " 'mlp_loss': 2.1884971276307716, 'mlp_accuracy': 0.69871795}\n",
    "#fold_7\n",
    "{'ae1_loss': 0.04105956664363158, 'ae1_mse': 0.04105957, 'ae1_mae': 0.16167267, 'ae2_loss': 0.0086138850819428,\n",
    " 'ae2_mse': 0.008613885, 'ae2_mae': 0.0026781328, \n",
    " 'mlp_loss': 2.5758261619470058, 'mlp_accuracy': 0.6602564}\n",
    "#fold_8\n",
    "{'ae1_loss': 0.042440927542239715, 'ae1_mse': 0.04244093, 'ae1_mae': 0.16471367, 'ae2_loss': 0.006808891734198749,\n",
    " 'ae2_mse': 0.006808892, 'ae2_mae': 0.0036072638, \n",
    " 'mlp_loss': 2.1458789446415047, 'mlp_accuracy': 0.6474359}\n",
    "#fold_9\n",
    "{'ae1_loss': 0.04173218314219447, 'ae1_mse': 0.04173218, 'ae1_mae': 0.16241072, 'ae2_loss': 0.0006675669974003222,\n",
    " 'ae2_mse': 0.00066756696, 'ae2_mae': 0.0012192972, \n",
    " 'mlp_loss': 2.428297372964712, 'mlp_accuracy': 0.6474359}\n",
    "#fold_10\n",
    "{'ae1_loss': 0.042473170761633844, 'ae1_mse': 0.04247317, 'ae1_mae': 0.16484436, 'ae2_loss': 0.003876802728520435, \n",
    " 'ae2_mse': 0.0038768027, 'ae2_mae': 0.0022777137, \n",
    " 'mlp_loss': 2.3337640212132382, 'mlp_accuracy': 0.7051282}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "avg_acc=np.array([0.69871795,0.6923077,0.6602564,0.67948717,0.6858974,0.69871795,0.6602564,0.6474359,0.6474359,0.7051282])\n",
    "avg_acc=(np.sum(avg_acc)/10)*100\n",
    "print(avg_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
